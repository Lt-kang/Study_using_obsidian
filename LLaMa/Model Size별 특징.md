# 1B(소형)
## 특징
- 파라미터가 적음
	- 계산량이 적음 -> 빠름
	- 작은 데이터에도 빠르게 변화하고 잘 적응함
	- over fitting 위험이 있음
- reasoning 능력 부족
- 독해력/문맥 유지력 약함


## 장점
- 가볍고 빠름
- 소규모 데이터에도 즉각 반응
- 간단한 task나 스타일 튜닝에 효율적
- inference 비용 낮음


## 단점
- 복잡한 문제를 풀지 못함
- 긴 문맥 이해력 부족
- 작은 데이터에도 빠르게 변화하지만 그만큼 좋지 못한 방향으로도 빠르게 변함
- 일반 지식 범위가 좁음
	- 10k Q&A를 학습할 경우
		- 일부는 기억하지만 일부는 잊거나 섞여버림
		- 모델의 Size가 기억해낼 수 있는 양임.
- 일반 능력(reasoning)이 낮기 때문에 fine tuning을 하더라도 한계가 있음


___

# 7B(중형)

## 특징
- 소형보다 일반 지식 범위 및 문맥(context) 유지 향상
- fine-tuning시 데이터에 반응하지만 1B보단 안정적


## 장점
- 대부분의 실무 task를 충분히 수행
- 스타일/도메인 튜닝도 안정적
- 작은 모델보다 over fitting에 대해 더 안정적임
- 작은 모델보다 똑똑함


## 단점
- vram 요구량 커짐(LoRA도 16GB 이상 권장)
- 학습 속도가 1B보다 더 느림
- 학습 데이터양이 1B보다 더 필요로 함
- 긴 문맥 처리 능력은 아직 제한적


___

# 13B(준-대형)

## 특징
- 일반적인 reasoning과 지식 처리에 강력함
- fine tuning시 데이터 편향에 대해 비교적 안정적

## 장점
- 전문 도메인 성능이 확연히 좋아짐
- 긴 문맥과 복잡한 질의응답에 강함

## 단점
- vram이 현실적으로 커지는 단위(24gb 이상)
- 많은 학습 데이터 필요
- inference 비용 증가


# 70B(대형)
## 특징
- 고급 reasoning, 깊은 문맥 추적, 일관성, 창의성 모두 훌륭
- 상용 LLM 품질에 가까움
- fine tuning시 매우 안정적이나 많은 데이터를 필요로 함

## 장점
- 수학/코딩/추론/번역 모두 상위권
- 이상한 답변 없이 답변이 안정적으로 출력됨
- 데이터 편향에 견고함
- 문맥 이해도 훌륭

## 단점
- vram 80gb 이상 / multi-GPU 필요
- fine tuning시 100k ~ 1M 데이터 필요
- 높은 비용(전기 + 시간 + 필요한 하드웨어)



# 요약
- 1B > 가볍게 실험하거나 특정 말투/업무 템플릿 주입에 완벽 / 고급 reasoning 작업은 무리
- 7B > 실제로 쓰는 서비스에 가까운 파인튜닝 최소 단위
- 13B > 도메인 전문 모델 제작에 적합한 주력급 모델
- 70B > 최고 품질을 원하고 예산이 있는 프로젝트 전용

|용도|적합 모델|
|---|---|
|단순 말투·스타일 튜닝|**1B**|
|기본 Q&A, 요약, 챗봇|**7B**|
|전문 분야(의료/법률/코딩 등)|**13B**|
|최고 품질, 강력한 reasoning|**70B**|

- 모델 크기가 크다
	- 학습 데이터가 많이 필요하다
	- 안정적인 답변을 출력할 수 있다
	- 많은 학습 데이터를 기억할 수 있다
	- reasoning 성능이 좋다
- 모델 크기가 작다
	- 학습 데이터가 적게 필요하다
	- 많은 학습 데이터를 기억할 수 없다
	- reasoning 성능이 좋지 못하다
